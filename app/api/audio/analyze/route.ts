import { NextRequest, NextResponse } from "next/server";
import { AssemblyAI } from "assemblyai";

// AssemblyAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const ASSEMBLYAI_API_KEY = process.env.ASSEMBLYAI_API_KEY;

if (!ASSEMBLYAI_API_KEY) {
  console.error("âŒ ASSEMBLYAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!");
  console.error("âš ï¸  .env.local íŒŒì¼ì— ASSEMBLYAI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.");
}

const client = new AssemblyAI({
  apiKey: ASSEMBLYAI_API_KEY || "",
});

// ìµœëŒ€ íŒŒì¼ í¬ê¸° (30MB)
const MAX_FILE_SIZE = 30 * 1024 * 1024;

// ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ í˜•ì‹
const SUPPORTED_FORMATS = [
  "audio/wav",
  "audio/mpeg",
  "audio/mp3",
  "audio/ogg",
  "audio/webm",
];

// ì¬ì‹œë„ ë¡œì§ (ì§€ìˆ˜ ë°±ì˜¤í”„)
async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  maxRetries: number = 3,
  baseDelay: number = 1000
): Promise<T> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn();
    } catch (error: any) {
      if (i === maxRetries - 1) throw error;

      // ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„
      const delay = baseDelay * Math.pow(2, i);
      console.log(`ì¬ì‹œë„ ${i + 1}/${maxRetries} - ${delay}ms í›„ ì¬ì‹œë„...`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  throw new Error("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼");
}

// ê°ì • ì ìˆ˜ë¥¼ í•œêµ­ì–´ë¡œ ë³€í™˜
function translateEmotionScores(scores: any): any {
  const emotionMap: { [key: string]: string } = {
    positive: "ê¸ì •ì ",
    negative: "ë¶€ì •ì ",
    neutral: "ì¤‘ë¦½ì ",
    happy: "í–‰ë³µ",
    sad: "ìŠ¬í””",
    angry: "í™”ë‚¨",
    excited: "í¥ë¶„",
    calm: "í‰ì˜¨",
    confident: "ìì‹ ê°",
    uncertain: "ë¶ˆí™•ì‹¤",
  };

  const translated: any = {};
  for (const [key, value] of Object.entries(scores)) {
    const koreanKey = emotionMap[key] || key;
    translated[koreanKey] = value;
  }
  return translated;
}

// ê°ì • ë ˆì´ë¸”ì„ í•œêµ­ì–´ë¡œ ë³€í™˜
function translateEmotionToKorean(label: string): string {
  const emotionMap: { [key: string]: string } = {
    positive: "ê¸ì •ì ",
    negative: "ë¶€ì •ì ",
    neutral: "ì¤‘ë¦½ì ",
    happy: "í–‰ë³µ",
    sad: "ìŠ¬í””",
    angry: "í™”ë‚¨",
    excited: "í¥ë¶„",
    calm: "í‰ì˜¨",
    confident: "ìì‹ ê°",
    uncertain: "ë¶ˆí™•ì‹¤",
  };
  return emotionMap[label] || label;
}

// í•œêµ­ì–´ ë¦¬í¬íŠ¸ ìƒì„±
function generateKoreanReport(analysisData: any): string {
  const { transcription, emotion, sentiment, auto_highlights, summary } =
    analysisData;

  let report = "ğŸ¤ **AI ë³´ì»¬ ë¶„ì„ ë¦¬í¬íŠ¸**\n\n";

  // íŠ¸ëœìŠ¤í¬ë¦½ì…˜
  if (transcription?.text) {
    report += `**ğŸ“ ìŒì„± ì¸ì‹ ê²°ê³¼:**\n${transcription.text}\n\n`;
  }

  // ê°ì • ë¶„ì„
  if (emotion?.label) {
    report += `**ğŸ˜Š ê°ì • ë¶„ì„:** ${emotion.label_ko || emotion.label}\n`;
    if (emotion.confidence) {
      report += `ì‹ ë¢°ë„: ${(emotion.confidence * 100).toFixed(1)}%\n\n`;
    }
  }

  // ê°ì • ì ìˆ˜
  if (emotion?.scores) {
    report += `**ğŸ“Š ê°ì • ì ìˆ˜:**\n`;
    const scores = emotion.scores_ko || emotion.scores;
    for (const [emotion, score] of Object.entries(scores)) {
      report += `- ${emotion}: ${(Number(score) * 100).toFixed(1)}%\n`;
    }
    report += "\n";
  }

  // ê°ì • ë¶„ì„ (AssemblyAI)
  if (sentiment?.sentiment) {
    report += `**ğŸ’­ ì „ì²´ ê°ì •:** ${sentiment.sentiment}\n`;
    if (sentiment.confidence) {
      report += `ì‹ ë¢°ë„: ${(sentiment.confidence * 100).toFixed(1)}%\n\n`;
    }
  }

  // ìë™ í•˜ì´ë¼ì´íŠ¸
  if (auto_highlights?.results && auto_highlights.results.length > 0) {
    report += `**â­ ì£¼ìš” í•˜ì´ë¼ì´íŠ¸:**\n`;
    auto_highlights.results.forEach((highlight: any, index: number) => {
      report += `${index + 1}. ${highlight.text} (${highlight.timestamp?.start}ì´ˆ)\n`;
    });
    report += "\n";
  }

  // ìš”ì•½
  if (summary) {
    report += `**ğŸ“‹ ìš”ì•½:**\n${summary}\n\n`;
  }

  // í™”ì ë¶„ë¦¬
  if (analysisData.utterances && analysisData.utterances.length > 0) {
    report += `**ğŸ‘¥ í™”ì ë¶„ì„:**\n`;
    const speakers = new Set(
      analysisData.utterances.map((u: any) => u.speaker)
    );
    report += `ì´ ${speakers.size}ëª…ì˜ í™”ìê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n`;
  }

  return report;
}

// ì§§ì€ ìš”ì•½ ìƒì„±
function generateShortSummary(analysisData: any): string {
  const { emotion, sentiment, summary } = analysisData;

  let summary_text = "";

  if (summary) {
    summary_text = summary;
  } else if (emotion?.label) {
    summary_text = `ê°ì •: ${emotion.label_ko || emotion.label}`;
  } else if (sentiment?.sentiment) {
    summary_text = `ê°ì •: ${sentiment.sentiment}`;
  } else {
    summary_text = "AI ë³´ì»¬ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.";
  }

  return summary_text;
}

export async function POST(request: NextRequest) {
  try {
    console.log("ğŸ¤ POST /api/audio/analyze ìš”ì²­ ìˆ˜ì‹  (AssemblyAI)");

    // AssemblyAI í† í° ì²´í¬
    if (!ASSEMBLYAI_API_KEY) {
      console.error("âŒ AssemblyAI API í† í°ì´ ì—†ìŠµë‹ˆë‹¤!");
      return NextResponse.json(
        {
          error: "AI ë¶„ì„ ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.",
          details: "ASSEMBLYAI_API_KEY is missing",
        },
        { status: 500 }
      );
    }

    // FormData íŒŒì‹±
    console.log("ğŸ“¦ FormData íŒŒì‹± ì¤‘...");
    const formData = await request.formData();
    const audioFile = formData.get("audio") as File;
    console.log("ğŸ“ íŒŒì¼ ìˆ˜ì‹ :", audioFile ? audioFile.name : "ì—†ìŒ");

    if (!audioFile) {
      return NextResponse.json(
        { error: "ì˜¤ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤." },
        { status: 400 }
      );
    }

    // íŒŒì¼ í¬ê¸° ê²€ì¦
    if (audioFile.size > MAX_FILE_SIZE) {
      return NextResponse.json(
        { error: "íŒŒì¼ í¬ê¸°ê°€ 30MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤." },
        { status: 400 }
      );
    }

    // íŒŒì¼ í˜•ì‹ ê²€ì¦
    if (!SUPPORTED_FORMATS.includes(audioFile.type)) {
      return NextResponse.json(
        { error: "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤." },
        { status: 400 }
      );
    }

    console.log(
      `ğŸ“ íŒŒì¼ ìˆ˜ì‹ : ${audioFile.name} (${(audioFile.size / 1024 / 1024).toFixed(2)}MB)`
    );

    // ì˜¤ë””ì˜¤ íŒŒì¼ì„ ArrayBufferë¡œ ë³€í™˜
    const arrayBuffer = await audioFile.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    console.log("ğŸ¤– AssemblyAI ë¶„ì„ ì‹œì‘...");

    // AssemblyAIì— ì˜¤ë””ì˜¤ ì—…ë¡œë“œ
    const uploadUrl = await retryWithBackoff(async () => {
      return await client.files.upload(buffer);
    });

    console.log("ğŸ“¤ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì™„ë£Œ:", uploadUrl);

    // AssemblyAI ë¶„ì„ ìš”ì²­
    const transcript = await retryWithBackoff(async () => {
      return await client.transcripts.create({
        audio: uploadUrl,
        language_code: "ko", // í•œêµ­ì–´
        sentiment_analysis: true, // ê°ì • ë¶„ì„
        auto_highlights: true, // ìë™ í•˜ì´ë¼ì´íŠ¸
        summarization: true, // ìš”ì•½
        speaker_labels: true, // í™”ì ë¶„ë¦¬
        entity_detection: true, // ê°œì²´ëª… ì¸ì‹
        iab_categories: true, // ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        content_safety_labels: true, // ì½˜í…ì¸  ì•ˆì „ì„±
        auto_chapters: true, // ìë™ ì±•í„°
        summarization_model: "informative", // ìš”ì•½ ëª¨ë¸
      });
    });

    console.log("â³ ë¶„ì„ ì§„í–‰ ì¤‘... (ID:", transcript.id, ")");

    // ë¶„ì„ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
    let finalTranscript;
    while (transcript.status !== "completed" && transcript.status !== "error") {
      await new Promise(resolve => setTimeout(resolve, 1000)); // 1ì´ˆ ëŒ€ê¸°
      finalTranscript = await client.transcripts.get(transcript.id);
      console.log("ğŸ“Š ë¶„ì„ ìƒíƒœ:", finalTranscript.status);
    }

    if (finalTranscript?.status === "error") {
      throw new Error(`AssemblyAI ë¶„ì„ ì‹¤íŒ¨: ${finalTranscript.error}`);
    }

    finalTranscript = finalTranscript || transcript;

    console.log("âœ… AssemblyAI ë¶„ì„ ì™„ë£Œ!");

    // ê²°ê³¼ íŒŒì‹±
    const analysisData = {
      transcription: {
        text: finalTranscript.text || "",
        language: finalTranscript.language_code || "ko",
        confidence: finalTranscript.confidence || 0.85,
      },
      emotion: {
        label:
          finalTranscript.sentiment_analysis_results?.[0]?.sentiment ||
          "neutral",
        label_ko: translateEmotionToKorean(
          finalTranscript.sentiment_analysis_results?.[0]?.sentiment ||
            "neutral"
        ),
        confidence:
          finalTranscript.sentiment_analysis_results?.[0]?.confidence || 0.5,
        scores:
          finalTranscript.sentiment_analysis_results?.[0]?.sentiment_scores ||
          {},
        scores_ko: translateEmotionScores(
          finalTranscript.sentiment_analysis_results?.[0]?.sentiment_scores ||
            {}
        ),
      },
      sentiment: {
        sentiment:
          finalTranscript.sentiment_analysis_results?.[0]?.sentiment ||
          "neutral",
        confidence:
          finalTranscript.sentiment_analysis_results?.[0]?.confidence || 0.5,
      },
      auto_highlights: finalTranscript.auto_highlights_results || null,
      summary: finalTranscript.summary || null,
      utterances: finalTranscript.utterances || [],
      entities: finalTranscript.entities || [],
      iab_categories: finalTranscript.iab_categories_results || null,
      content_safety_labels:
        finalTranscript.content_safety_labels_results || null,
      chapters: finalTranscript.chapters || [],
      metadata: {
        duration_seconds: finalTranscript.audio_duration || 0,
        file_name: audioFile.name,
        words_count: finalTranscript.words?.length || 0,
      },
      cost_estimate_usd: (0.00065 * (finalTranscript.audio_duration || 0)) / 60, // AssemblyAI ê°€ê²©
    };

    // í•œêµ­ì–´ ë¦¬í¬íŠ¸ ìƒì„±
    console.log("ğŸ“ í•œêµ­ì–´ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...");
    const reportKo = generateKoreanReport(analysisData);
    const shortSummary = generateShortSummary(analysisData);

    // ìµœì¢… ê²°ê³¼
    const result = {
      ...analysisData,
      report_ko: reportKo,
      summary_ko: shortSummary,
    };

    console.log("ğŸ‰ AssemblyAI ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!");
    return NextResponse.json(result);
  } catch (error: any) {
    console.error("âŒ AssemblyAI ë¶„ì„ ì˜¤ë¥˜:", error);

    // ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if (error.message?.includes("rate limit")) {
      return NextResponse.json(
        { error: "API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”." },
        { status: 429 }
      );
    }

    if (error.message?.includes("authentication")) {
      return NextResponse.json(
        { error: "API ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”." },
        { status: 401 }
      );
    }

    if (error.message?.includes("quota")) {
      return NextResponse.json(
        { error: "API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”." },
        { status: 429 }
      );
    }

    return NextResponse.json(
      {
        error: "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        details:
          process.env.NODE_ENV === "development" ? error.message : undefined,
      },
      { status: 500 }
    );
  }
}

// GET ìš”ì²­ - API ìƒíƒœ í™•ì¸
export async function GET() {
  return NextResponse.json({
    status: "ok",
    message: "AI Vocal Analysis API (AssemblyAI)",
    version: "2.0.0",
    provider: "AssemblyAI",
    endpoints: {
      POST: "/api/audio/analyze - ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„",
    },
    features: [
      "ìŒì„± ì¸ì‹ (Speech-to-Text)",
      "ê°ì • ë¶„ì„ (Sentiment Analysis)",
      "ìë™ í•˜ì´ë¼ì´íŠ¸ (Auto Highlights)",
      "ìš”ì•½ (Summarization)",
      "í™”ì ë¶„ë¦¬ (Speaker Labels)",
      "ê°œì²´ëª… ì¸ì‹ (Entity Detection)",
      "ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (IAB Categories)",
      "ì½˜í…ì¸  ì•ˆì „ì„± (Content Safety)",
      "ìë™ ì±•í„° (Auto Chapters)",
    ],
  });
}
